{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T19:55:51.271503800Z",
     "start_time": "2024-11-14T19:55:43.895998700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.virtualenvs\\xlab-ml-service\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:295: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "from omegaconf import OmegaConf\n",
    "from IPython.display import Audio, display\n",
    "from torch import nn\n",
    "\n",
    "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml',\n",
    "                               'latest_silero_models.yml',\n",
    "                               progress=False)\n",
    "models = OmegaConf.load('latest_silero_models.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading silero v1 TTS model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\user/.cache\\torch\\hub\\snakers4_silero-models_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "from omegaconf import OmegaConf\n",
    "from IPython.display import Audio, display\n",
    "from torch import nn\n",
    "\n",
    "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml',\n",
    "                               'latest_silero_models.yml',\n",
    "                               progress=False)\n",
    "models = OmegaConf.load('latest_silero_models.yml')\n",
    "\n",
    "language = 'ru'\n",
    "speaker = 'kseniya_16khz'\n",
    "device = torch.device('cuda:0')\n",
    "model, symbols, sample_rate, example_text, apply_tts = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                                                      model='silero_tts',\n",
    "                                                                      language=language,\n",
    "                                                                      speaker=speaker)\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T20:19:40.394258600Z",
     "start_time": "2024-11-14T20:19:39.266721600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View the model layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model tacotron block"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.jit.script(model.tacotron).code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def forward(self,\n",
    "            inputs: Tensor,\n",
    "            max_decoder_steps: Optional[int] = None) -> Tuple[Tensor, Tensor]:\n",
    "    embedding = self.embedding\n",
    "    embedded_inputs = torch.transpose((embedding).forward(inputs, ), 1, 2)\n",
    "    encoder = self.encoder\n",
    "    encoder_outputs = (encoder).forward(embedded_inputs, )\n",
    "    decoder = self.decoder\n",
    "    _0 = (decoder).forward(encoder_outputs, max_decoder_steps, )\n",
    "    mel_outputs, gate_outputs, alignments, mel_lengths, = _0\n",
    "    postnet = self.postnet\n",
    "    mel_outputs_postnet = (postnet).forward(mel_outputs, )\n",
    "    mel_outputs_postnet0 = torch.add(mel_outputs, mel_outputs_postnet)\n",
    "    if torch.gt(torch.size(inputs, 0), 1):\n",
    "        mel_outputs_postnet2 = (self).parse_output(mel_outputs_postnet0, mel_lengths, )\n",
    "        mel_outputs_postnet1 = mel_outputs_postnet2\n",
    "    else:\n",
    "        mel_outputs_postnet1 = mel_outputs_postnet0\n",
    "    return (mel_outputs_postnet1, mel_lengths)  #%%"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T22:04:09.713786900Z",
     "start_time": "2024-11-14T22:04:09.708726500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.virtualenvs\\xlab-ml-service\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1410.)\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example_text = 'В недрах тундры выдры в гетрах тырят в вёдра ядра кедров. '\n",
    "cleaned_example_text = \"\".join([c if c in symbols else \" \" for c in example_text])\n",
    "\n",
    "speaker_id = torch.tensor(0).to(device)\n",
    "embeder = model.tacotron.embedding.to(device)\n",
    "encoder = model.tacotron.encoder.to(device)\n",
    "decoder = model.tacotron.decoder.to(device)\n",
    "\n",
    "input_tensor = torch.LongTensor([symbols.index(c) for c in cleaned_example_text]).unsqueeze(0).to(device)\n",
    "embedded_inputs = embeder(input_tensor)\n",
    "embedded_inputs = torch.transpose(embedded_inputs, 1, 2)\n",
    "encoder_output = encoder(embedded_inputs)\n",
    "mel_outputs, gate_outputs, alignments, mel_lengths = decoder(encoder_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T22:09:49.917427800Z",
     "start_time": "2024-11-14T22:09:47.897709100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mel_outputs torch.Size([1, 128, 1000])\n",
      "gate_outputs torch.Size([1, 1000])\n",
      "alignments torch.Size([1, 1000, 58])\n",
      "mel_lengths torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(\"mel_outputs\", mel_outputs.shape)  # <- use this as speech data representation\n",
    "print(\"gate_outputs\", gate_outputs.shape)\n",
    "print(\"alignments\", alignments.shape)\n",
    "print(\"mel_lengths\", mel_lengths.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T22:10:08.592690600Z",
     "start_time": "2024-11-14T22:10:08.583788Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the context of Silero's Text-to-Speech (TTS) models, particularly those inspired by architectures like Tacotron 2, several key outputs are generated during thesynthesis process:\n",
    "\n",
    "### Mel Outputs (mel_outputs):\n",
    "\n",
    "Definition: These are sequences of mel-spectrogram frames representing the synthesized speech's frequency content over time.\n",
    "Purpose: Mel-spectrograms serve as intermediate representations that are subsequently converted into audible waveforms using vocoders.\n",
    "\n",
    "### Gate Outputs (gate_outputs):\n",
    "\n",
    "Definition: These are scalar values produced at each decoder time step, indicating the probability of the synthesis process being complete.\n",
    "Purpose: Gate outputs help the model determine when to stop generating frames, ensuring efficient and accurate speech synthesis.\n",
    "\n",
    "### Alignments (alignments):\n",
    "\n",
    "Definition: Alignments are attention maps that depict the relationship between input text tokens and the generated mel-spectrogram frames.\n",
    "Purpose: They provide insights into how the model aligns input text with the corresponding speech, which is crucial for understanding and debugging the synthesis process.\n",
    "### Mel Lengths (mel_lengths):\n",
    "\n",
    "Definition: These indicate the number of mel-spectrogram frames generated for each input sequence.\n",
    "Purpose: Mel lengths are essential for batching and padding operations, ensuring that sequences of varying lengths are handled appropriately during training and inference."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
